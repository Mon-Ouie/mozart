<Chapter id="chapter.scanner">
  <Title/The Gump Scanner Generator/
  <P>
    This chapter describes the &Gump; Scanner Generator.  Its input consists
    of an &Oz; source with embedded scanner specifications; the output
    implements each scanner by an &Oz; class.
  <Para class=apropos><Title/Definitions/
    A <Def>scanner</Def> is a program that performs lexical analysis,
    which means that it transforms a stream of characters into a stream of
    <Def>tokens</Def>.  The text is read from left to right.  During this
    process, sequences of characters are grouped into <Def>lexemes</Def>
    according to user-defined rules, specified by so-called <Def>regular
    expressions</Def> and associated <Def>semantic actions</Def>.  An
    action computes tokens from a lexeme, each consisting of a <Def>token
    class</Def> and an optional <Def>token value</Def>, which are appended
    to the token stream.  The process is iterated until the end of the
    character stream is reached.
  <P>
    This chapter first describes the basic principles of the &Gump; Scanner
    Generator by means of an example in <Ptr to="section.scanner.example">.
    A more detailed reference is then given in <Ptr
    to="section.scanner.reference">.
  <Section id="section.scanner.example">
    <Title/Example/
    <P>
      As a running example we will specify, throughout the manual, a front-end
      for a compiler or an interpreter for a small functional language <Name
      type=language>Lambda</Name>.  In this section we will define the scanner
      for this language, in <Ptr to="section.parser.example"> we build a
      parser on top of this scanner.
    <SubSection>
      <Title/Writing a Scanner Specification/
      <P>
        <Ptr to="program.scanner.example"> shows the specification of the
        sample scanner we will consider in this section.  In the following
        we will examine this example line by line.
        <Figure float id="program.scanner.example" class=program>
          <Caption>The <<LambdaScanner>> scanner specification.</Caption>
          <P> <!--**-->
            <Code.Extern display to="LambdaScanner.ozg">
        </Figure>
      <Para class=apropos><Title/Class Descriptors/
        At the first glance the scanner specification closely resembles a
        class definition with some extra elements, introduced by the keyword
        <<scanner>> instead of <<class>>.  This is intentional, since it
        will ultimately be replaced by a class.  This is why all descriptors
        allowed in a class definition are also allowed at the beginning of a
        scanner specification.  Consider the <<from>>, <<attr>> and <<meth>>
        constructs used in lines 2 to&nbsp;10.
      <Para class=apropos><Title/Lexical Abbreviations/
        The scanner-specific declarations begin at line&nbsp;12.  Two
        kinds of definition can be introduced by the keyword <<lex>>:
        the definition of a <Def>lexical abbreviation</Def>, as seen
        in lines 12 to&nbsp;15, and the <Def>lexical rules</Def> found
        from line&nbsp;17 to the end of the specification.  A lexical
        abbreviation <<lex ?{I} = &lt;?{R}&gt; end>> simply associates
        an identifier&nbsp;<Var type=meta>I</Var> with a given regular
        expression&nbsp;<Var type=meta>R</Var>.  The construct&nbsp;<Var
        type=meta>I</Var> in other regular expressions is then expanded
        to&nbsp;<<(?{R})>>.
      <P>
        Note that regular expressions use the same syntax as regular
        expressions in &flex;&nbsp;<Ptr to="paxson95">, with a few exceptions
        (detailed in <Ptr to="section.scanner.syntax">).  Furthermore, we must
        either enclose them in angle brackets or give them as &Oz; strings.
        (The latter proves useful when the angle-bracketed version confuses
        Emacs' fontification mode, but is a bit harder to read, since more
        characters must be escaped.)
      <P>
        The example defines four lexical abbreviations: <<digit>> stands for
        a decimal digit, <<letter>> for an uppercase or lowercase letter;
        <<id>> defines the syntax of identifiers to consist of a letter,
        followed by an arbitrary sequence of letters and digits; and finally,
        <<int>> defines the syntax of positive decimal integers as a nonempty
        sequence of digits.
      <Para class=apropos><Title/Lexical Rules/
        Lexical rules of the form <<lex &lt;?{R}&gt; ?{S} end>> are
        more interesting, since the set of these is the actual scanner
        specification.  Upon a match of a prefix of the input character
        stream with the regular expression&nbsp;<Var type=meta>R</Var>, the
        statement&nbsp;<Var type=meta>S</Var> is executed as a method body
        (&ie;, the object state may be accessed and modified).  Two methods
        are provided by the mixin class <<GumpScanner.'class'>> (inherited
        from in line&nbsp;2) to append tokens to the token stream:
        <<putToken1>>, which appends a token of a given class without a
        value (<<unit>> being used instead), and <<putToken>>, which allows
        a specific token value to be provided.  Token classes may be
        represented by arbitrary &Oz; values, but the parser generator in
        <Ptr to="chapter.parser"> expects them to be atoms.  In lines 18
        and&nbsp;21 you can see how constants are used as token classes.
        In line&nbsp;33 the token class is computed from the lexeme.
      <Para class=apropos><Title/Accessing the Lexeme/
        The lexeme itself may be accessed in several ways.  The method
        <<getAtom>> returns the lexeme as an atom, which is the representation
        for identifier token values chosen in line&nbsp;25.  The method
        <<getString>> returns the lexeme as a string, such as in line&nbsp;28,
        where it is subsequently converted to an integer.
      <P>
        The remaining lexical rules are easily explained.  Lines 36
        and&nbsp;37 respectively describe that whitespace and comments
        are to be ignored.  This stems from the fact that neither <<putToken1>>
        nor <<putToken>> is called.  (Note that an action can also invoke
        them several times to append multiple tokens to the token stream,
        just as it may chose not to invoke them at all to simply ignore the
        lexeme or only produce side effects.)  The rule in line&nbsp;38
        ignores any matched newlines, but updates the line counter attribute
        <<LineNumber>> as it does so.  The rule in line&nbsp;41 reports any
        remaining unmatched characters in the input as lexical errors and
        returns the token <<'error'>> which the parser can recognize as an
        erroneous token.
      <Para class=apropos><Title/End-of-File Rules/
        The final rule, in line&nbsp;46, has the special syntax
        <<&lt;&lt;EOF&gt;&gt;>> (it might also have been written as
        <<"&lt;&lt;EOF&gt;&gt;">>) and only matches the end of the character
        stream.  It returns the token <<'EOF'>> which can be recognized by the
        parser as the end of input.  Note that the action might just as well
        open another file to read from.
      <P>
        More information about acceptable sets of regular expressions in
        scanner specifications, conflict resolution and grouping into
        lexical modes is given in <Ptr to="section.scanner.syntax">.
    <SubSection>
      <Title/Invoking Gump/
      <P>
        Now that we have finished writing our specification, we want to
        translate it into an Oz class definition that implements our scanner.
        For this, we issue the compiler directive
        <<<\switch +gump>>>
        whereupon the compiler will accept &Gump; specifications.
      <Para class=apropos><Title/Running Gump/
        Save the above specification in a file <File/LambdaScanner.ozg/.
        The extension <File/.ozg/ indicates that this file contains &Oz;
        code with additional &Gump; definitions, so that Emacs will fontify
        &Gump; definitions correctly.  Feeding
        <<<\insert LambdaScanner.ozg>>>
        will process this file.  Switch to the Compiler buffer (via <Kbd
        >C-c C-c</Kbd>) to watch &Gump;'s status messages and any errors
        occurring during the translation.  Some messages may also appear in
        the Emulator buffer (displayed via <Kbd>C-c C-e</Kbd>).
      <Para class=apropos><Title/Output Files/
        When the translation is finished, you will notice several new files
        in the current working directory.  These will be named after your
        <<scanner>> specification.  Suppose your scanner was called&nbsp;<<S>>,
        then you will find files <File/S.l/, <File/S.C/, <File/S.o/ and
        <File/S.dl/.  The first three are intermediate results (respectively
        the input file for &flex;, the &flex;-generated C++&nbsp;file and
        the object code produced by the C++&nbsp;compiler) and the last one is
        the resulting dynamic library used by the generated scanner, loaded
        via <<Foreign.load>>.
    <SubSection><Title>Using the Generated Scanner
      <P>
        <Ptr to="program.scanner.test"> shows a sample program running our
        generated scanner.
        <Figure float id="program.scanner.test" class=program>
          <Caption>A program making use of the generated scanner.</Caption>
          <P>
            <Code.Extern to="TestScanner.ozg">
        </Figure>
      <P>
        The generated <<LambdaScanner>> class is instantiated as <<MyScanner>>.
        We have to call the method <<init()>> first to initialize the internal
        structures of the <<GumpScanner>>.
      <Para class=apropos><Title/Requesting Tokens/
        The procedure <<GetTokens>> repeatedly invokes the <<GumpScanner>>
        method
        <<<getToken(??{X} ??{Y})>>>
        which returns the next token's token class in&nbsp;<Var type=meta
        >X</Var> and token value in&nbsp;<Var type=meta>Y</Var> and removes
        it from the token stream.  <<GetTokens>> exits when the end of the
        token stream is reached, which is recognized by the token class
        <<'EOF'>>.
      <Para class=apropos><Title/Providing Inputs/
        To actually start scanning we have to provide an input character
        stream.  This is done via one of the methods
        <<<scanFile(?+{FileName})>>>
        or
        <<<scanVirtualString(?+{V})>>>
        Each of these pushes the currently used buffer (if any) upon an
        internal stack of buffers and builds a new buffer from the given
        source.  Each time the end of a buffer is reached, the
        <<&lt;&lt;EOF&gt;&gt;>> rule is matched.  This may pop a buffer
        and continue scanning the next-outer buffer where it left off,
        using the <<closeBuffer>> method described in <Ptr
        to="section.scanner.class">.
      <Para class=apropos><Title/Closing Scanners/
        When a scanner is not used anymore, it should be sent the message
        <<<close()>>>
        so that it can close any open files and release any allocated buffers.
        (This is even necessary when scanning virtual strings due to the
        underlying implementation in&nbsp;C.)
      <P>
        The following is a sample input for the scanner.  The above example
        expects this to be placed in the file <File/Lambda.in/ in the
        current directory:
        <Code.Extern display proglang=lambda to="Lambda.in">
  <Section id="section.scanner.reference">
    <Title/Reference/
    <P>
      This section is intended to serve as a reference for the user of
      the &Gump; Scanner Generator.  It details the syntax of the embedded
      scanner specification language in <Ptr to="section.scanner.syntax">,
      which options are supported and how they are specified in <Ptr
      to="section.scanner.params"> and finally the runtime part of the
      Scanner Generator, the mixin class <<GumpScanner.'class'>>, in
      <Ptr to="section.scanner.class">.
    <SubSection id="section.scanner.syntax">
      <Title/Syntax of the Scanner Specification Language/
      <P>
        The notation used here for specifying the syntax of the specification
        language is a variant of <Name type=formalism>BNF</Name> and is
        defined in <Ptr to="appendix.notation">.
      <P>
        A scanner specification is allowed anywhere as an &Oz; statement:
        <Grammar.Rule>?={phrase}
          <Grammar.Alt type="add">?={scanner specification}</Grammar.Alt>
      <P>
        It is similar to a class definition, except that it is introduced
        by the keyword <<scanner>>, must be named by a variable (and not an
        arbitrary term), since this is used for assigning file names, and
        allows for additional descriptors after the usual class descriptors.
        <Grammar.Rule>?={scanner specification}
          <Grammar.Alt type="def"><<scanner>> ?={variable}</Grammar.Alt>
          <Grammar.Alt>{ ?={class descriptor} }</Grammar.Alt>
          <Grammar.Alt>{ ?={method} }</Grammar.Alt>
          <Grammar.Alt>{ ?={scanner descriptor} }+</Grammar.Alt>
          <Grammar.Alt><<end>></Grammar.Alt>
      <P>
        A <Def>lexical abbreviation</Def> associates an identifier with a
        regular expression, which can then be referenced in subsequent lexical
        abbreviations or any lexical rules by enclosing the identifier in
        curly brackets.  The regular expression is additionally parenthesized
        when it is expanded.
        <Grammar.Rule>?={lexical abbreviation}
          <Grammar.Alt type="def"
            ><<lex>> ?={atom} <<=>> ?={regex} <<end>></Grammar.Alt>
          <Grammar.Alt type="or"
            ><<lex>> ?={variable} <<=>> ?={regex} <<end>></Grammar.Alt>
      <P>
        The definition of a <Def>lexical rule</Def> is similar to the
        definition of a method.  However, its head consists of a regular
        expression; when this is matched, the body of the lexical rule is
        executed (as a method).
        <Grammar.Rule>?={lexical rule}
          <Grammar.Alt type=def><<lex>> ?={regex}</Grammar.Alt>
          <Grammar.Alt>[ ?={phrase} <<in>> ] ?={phrase}</Grammar.Alt>
          <Grammar.Alt><<end>></Grammar.Alt>
      <P>
        Regular expressions may be annotated with <Def>lexical modes</Def>.
        Each lexical mode constitutes an independent sub-scanner:  At any time
        a certain mode is active; in this mode only the regular expressions
        annotated by it can be matched.  All lexical rules defined within
        the scope of a lexical mode are annotated with this lexical mode.
        A lexical mode may <Def>inherit</Def> from other lexical modes; all
        regular expressions in these modes are then annotated with the
        inheriting lexical mode as well.  Lexical modes inherit from all
        lexical modes they are nested in.  Lexical rules written at top-level
        are annotated with the implicitly declared mode <<INITIAL>>.
        <Grammar.Rule>?={lexical mode}
          <Grammar.Alt type="def"
            ><<mode>> ?={variable} [ <<from>> { ?={variable} }+ ]
          <Grammar.Alt>{ ?={mode descriptor} }</Grammar.Alt>
          <Grammar.Alt><<end>></Grammar.Alt>
        <Grammar.Rule>?={mode descriptor}
          <Grammar.Alt type=def>?={lexical rule}</Grammar.Alt>
          <Grammar.Alt type=or>?={lexical mode}</Grammar.Alt>
      <SubSubSection>
        <Title/Syntax of Regular Expressions/
        <P>
          Regular expressions ?={regex} correspond to the regular expressions
          used in &flex;&nbsp;<Ptr to="paxson95" info="Version 2.5.2">
          with a few exceptions:
          <List>
            <Item>
              <P.silent><!--**-->
                &Gump; regular expressions are either enclosed in angle
                brackets or given as &Oz; strings.
            <Item>
              <P.silent><!--**-->
                The angle-bracket annotation with lexical modes is not
                supported by &Gump;; use scopes of lexical modes instead.  Note
                that several distinct lexical mode definitions may occur for
                the same lexical mode name as long as no inheritance cycles are
                created.
          </List>
        <P>
          Due to the underlying use of &flex;, the names of lexical
          abbreviations are restricted to the syntax allowed in &flex;
          name definitions.
      <SubSubSection>
        <Title/Ambiguities and Errors in the Rule Set/
        <P>
          Tokenization is performed by a left-to-right scan of the input
          character stream.  If several rules match a prefix of the input,
          then the rule matching the longest prefix is preferred.  If
          several rules match the same (longest) prefix of the input,
          then two rules may be applied to disambiguate the match (see
          <Ptr to="section.scanner.params"> on how to select the rule):
          <List>
            <Entry>First-fit.
            <Item>
              <P.silent><!--**-->
                The rule notated first in the scanner specification is
                preferred.  In this case, every conflict can be uniquely
                resolved.  Two errors in the rule set are possible: holes
                and completely covered rules (see below).
            <Entry>Best-fit.
            <Item>
              <P.silent><!--**-->
                Suppose two conflicting rules are rule&nbsp;<Math>r_1</Math>
                and rule&nbsp;<Math>r_2</Math>, which are annotated by sets
                of lexical modes <Math>L_1</Math> and&nbsp;<Math>L_2</Math>
                respectively.  Then <Math>r_1</Math> is preferred
                over&nbsp;<Math>r_2</Math> if and only if the following
                conditions hold:
                <Math display>
                  S_1 \subseteq S_2 \; \wedge \; L(r_1) \subseteq L(r_2)
                </Math>
                where <Math>L(r)</Math> is the language generated by a regular
                expression&nbsp;<Math>r</Math>, that is, the set of strings
                that match&nbsp;<Math>r</Math>.  Intuitively, this rule
                means that <Math>r_1</Math> is <Q/more specialized
                than/&nbsp;<Math>r_2</Math>.  Additionally to the errors
                possible in the rule set in the first-fit case, here the
                situation may arise that the rule set is not well-ordered
                &wrt; the <Q/more specialized than/ relation.
          </List>
        <P>
          The following errors in the rule set may occur:
          <List>
            <Entry>Holes in the rule set.
            <Item>
              <P.silent><!--**-->
                For some input (in some mode), no true prefix is matched by
                any rule.
            <Entry>Completely covered rules.
            <Item>
              <P.silent><!--**-->
                A rule&nbsp;<Math>r</Math> is never matched because for every
                prefix in&nbsp;<Math>L(r)</Math> exists another rule&nbsp;<Math
                >s</Math> which is preferred over&nbsp;<Math>r</Math>.
            <Entry>Non well-orderedness.
            <Item>
              <P.silent><!--**-->
                Two rules&nbsp;<Math>r_1</Math> and&nbsp;<Math>r_2</Math>
                are in conflict in the best-fit case, but neither is
                <Math>r_1</Math> more specialized than&nbsp;<Math>r_2</Math>
                nor the other way round, and no rule or set of rules exists
                that covers the intersection <Math>L(r_1) \cap L(r_2)</Math>.
          </List>
    <SubSection id="section.scanner.params">
      <Title/Parameters to Scanner Generation/
      <P>
        The &Gump; Scanner Generator supports several configuration parameters,
        which may be set on a per-scanner basis via the use of compiler
        directives.
      <P>
        Due to the implementation of scanners in&nbsp;C, a unique prefix is
        required for each scanner to avoid symbol conflicts when several
        scanners reside at the same time in the Mozart system.  The following
        directive allows this prefix to be changed (the default <<zy>> is all
        right if only a single scanner is used at any time):
        <<<\gumpscannerprefix ?{atom}>>>
      <P>
        <Ptr to="table.scanner.switches"> summarizes some compiler switches
        that control the &Gump; Scanner Generator.
        <Figure float id="table.scanner.switches" class=table>
          <Caption>Compiler switches for the Gump Scanner Generator.</Caption>
          <P><!--**-->
          <Table>
            <TR>
              <TH>Switch
              <TH>Effect
            <TR>
              <TD><Code><Span class=ignore>\switch +</Span
                >gumpscannerbestfit</Code>
              <TD>Use best-fit instead of first-fit disambiguating
            <TR>
              <TD><Code><Span class=ignore>\switch +</Span
                >gumpscannercaseless</Code>
              <TD>Generate a case-insensitive scanner
            <TR>
              <TD><Code><Span class=ignore>\switch +</Span
                >gumpscannernowarn</Code>
              <TD>Suppress warnings from &flex;
          </Table>
        </Figure>
    <SubSection id="section.scanner.class">
      <Title/The Mixin Class <<GumpScanner.'class'>>/
      <P>
        The module <<GumpScanner>> defines the runtime support needed by
        &Gump;-generated scanners.  All operations and data are encapsulated
        in the mixin class <<GumpScanner.'class'>> that scanners have to
        inherit from in order to be executable.
      <P>
        The mixin class expects the following features and methods to be
        defined by derivate classes.  (It is a good idea not to define any
        class members whose name begins with <<lex&ellipsis;>> since these
        may be used for internals of the Scanner Generator.)
        <List>
          <Entry><<feat lexer>>
          <Item>
            <P.silent><!--**-->
              This feature must contain the scanner-specific loaded foreign
              functions, which includes the generated scanner tables.
          <Entry><<meth lexExecuteAction(?+{I})>>
          <Item>
            <P.silent><!--**-->
              This method is called each time a regular expression is matched.
              Regular expressions are assigned unique integers; the parameter
              to this method indicates which rule's associated action is to be
              run.
        </List>
        The <<GumpScanner.'class'>> class defines some user functionality
        that is to be used either by users of the generated scanner or by
        the semantic actions in the scanner itself.
        <List>
          <Entry><<meth init()>>
          <Item>
            <P.silent><!--**-->
              This initializes the internal structures of the
              <<GumpScanner.'class'>>.  This must be called before any other
              method of this class.
          <Entry><<meth setMode(?+{I})>>
          <Item>
            <P.silent><!--**-->
              The operation mode of the scanner is set to the lexical
              mode&nbsp;<Var type=meta>I</Var>.  Lexical modes are represented
              internally as integers.  Since modes are identified by variables,
              the class generation phase wraps a <<local &ellipsis; end>>
              around the class equating the mode variables to the assigned
              unique integers.
          <Entry><<meth currentMode(??{I})>>
          <Item>
            <P.silent><!--**-->
              This returns the integer identifying the lexical mode the scanner
              currently operates in.
          <Entry><<meth getAtom(??{A})>>
          <Item>
            <P.silent><!--**-->
              This method is used to access the lexeme last matched.  It is
              returned as an atom in the variable&nbsp;<Var type=meta>A</Var>.
              Note that if the lexeme contains a <Name type=char>NUL</Name>
              character (ISO&nbsp;0) then only the text up to the first
              <Name type=char>NUL</Name> but excluding it is returned.
          <Entry><<meth getString(??{S})>>
          <Item>
            <P.silent><!--**-->
              This method returns the lexeme as a string in the
              variable&nbsp;<Var type=meta>S</Var>.  The restrictions
              concerning <<getAtom>> do not apply for <<getString>>.
          <Entry><<meth getLength(??{I})>>
          <Item>
            <P.silent><!--**-->
              This method returns the length of the lexeme (number of
              characters matched).
          <Entry><<meth putToken(?+{X} ?_{Y})>>
          <Item>
            <P.silent><!--**-->
              This method may be used to append a token with token
              class&nbsp;<Var type=meta>X</Var> and value&nbsp;<Var type=meta
              >Y</Var> to the token stream.  (Actually, the token class may be
              an arbitrary &Oz; value, but atoms and the integers between 0
              and&nbsp;255 are the only representations understood by
              &Gump;-generated parsers.)
          <Entry><<meth putToken1(?+{X})>>
          <Item>
            <P.silent><!--**-->
              This method may be used to append a token with token
              class&nbsp;<Var type=meta>X</Var> and value <<unit>> to the
              token stream.
          <Entry><<meth getToken(??{X} ?_{Y})>>
          <Item>
            <P.silent><!--**-->
              The next token is removed from the token stream and returned.
              The token class is returned in&nbsp;<Var type=meta>X</Var>
              and its value in&nbsp;<Var type=meta>Y</Var>.
          <Entry><<meth input(??{C})>>
          <Item>
            <P.silent><!--**-->
              The next (unmatched) character is removed from the character
              stream and returned in&nbsp;<Var type=meta>C</Var>.
          <Entry><<meth unput(?+{C})>>
          <Item>
            <P.silent><!--**-->
              A character&nbsp;<Var type=meta>C</Var> is prepended to the
              input character stream.  This is next used by matching operations
              or returned by <<input>>.
          <Entry><<meth scanFile(?+{V})>>
          <Item>
            <P.silent><!--**-->
              This method causes the currently scanned buffer (if any) to be
              pushed on a stack of active buffers.  A new buffer is created
              from the file with name&nbsp;<Var type=meta>V</Var> and scanned.
              If the file does not exist, the error exception
              <<gump(fileNotFound ?_{V})</Code> with the filename
              in&nbsp;<Var type=meta>V</Var> is raised; the default
              treatment is the invocation of a custom error printer.
          <Entry><<meth scanVirtualString(?+{V})>>
          <Item>
            <P.silent><!--**-->
              Like <<scanFile>>, but scans a virtual string&nbsp;<Var
              type=meta>V</Var>.  If&nbsp;<Var type=meta>V</Var> contains
              <Name type=char>NUL</Name> characters (ISO&nbsp;0) then the
              virtual string is only scanned up to and excluding the first
              <Name type=char>NUL</Name> character.
          <Entry><<meth setInteractive(?+{B})>>
          <Item>
            <P.silent><!--**-->
              Each buffer may be either interactive or non-interactive.  An
              interactive buffer only reads as many characters as are needed
              to be considered to decide about a match; a non-interactive
              buffer may read ahead.  This method allows the topmost buffer
              on the stack to be set to interactive (if <Var type=meta>B</Var>
              is <<true>>) or non-interactive (if <Var type=meta>B</Var> is
              <<false>>).  New buffers are always created as non-interactive
              buffers.
          <Entry><<meth getInteractive(??{B})>>
          <Item>
            <P.silent><!--**-->
              Whether the topmost buffer on the buffer stack is interactive
              is returned.
          <Entry><<meth setBOL(?+{B})>>
          <Item>
            <P.silent><!--**-->
              The beginning-of-line (BOL) flag indicates whether the
              beginning-of-line regular expression <Code><Span class=ignore
              >lex &lt;</Span>^<Span class=ignore>&gt;</Span></Code> may be
              matched.  This flag is true at the beginning of a buffer or
              after a newline has been scanned.  The flag's value may be set
              at will with this method.
          <Entry><<meth getBOL(??{B})>>
          <Item>
            <P.silent><!--**-->
              Returns the current state of the beginning-of-line flag.
              See the <<setBOL>> method.
          <Entry><<meth closeBuffer()>>
          <Item>
            <P.silent><!--**-->
              Closes the topmost buffer on the buffer stack and resumes
              scanning from the buffer on the new stack top (if any).  If the
              buffer stack is or becomes empty through this operation, only
              tokens with class <<'EOF'>> and value <<unit>> are returned
              subsequently (until a new buffer is created).
          <Entry><<meth close()>>
          <Item>
            <P.silent><!--**-->
              Closes all buffers on the buffer stack.  Before calling any
              other methods, you should call <<init()>> again.
        </List>
</Chapter>
